---
title: "01_clean_data.Rmd"
author: "Vinay K L"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo = F}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=80),tidy=TRUE)
```

```{r loading libraries, include=FALSE}
library(rvertnet)
library(tidyverse)
library(rgdal)
library(dplyr)
library(lubridate)
library(countrycode)
library(stringr)
library(fuzzyjoin)
library(readr)
```

## get the data2 using rvetnet
```{r datascraping, include=FALSE}
bigsearch(class = "aves", rfile = "aves_vertnet_records", email = "vkl1@lsu.edu") 
```

## Loading the datasets
```{r dataset 1}
data1 <- read.csv("../data/vertnet_latest_birds.csv", sep = "," , header = TRUE)
```

```{r dataset 2, warning=FALSE}
data2 <- read.csv("../data/aves_vertnet_records-43452c1446904be6ba9641c86f891234.tsv", sep = "\t", header = TRUE)
```

```{r, dataset 3, warning=FALSE}
# There seems to be some kind of disordinance with the rvertnet bigsearch - third request produced larger dataset - let's try and see how it pans out. 
data3 <- read.csv("../data/vertnet_6mil_records-2ea2e413e6584682a68b08d3a56c8493.tsv", sep ="\t", header = TRUE)
```

## inspecting the datasets
```{r message=FALSE}
head(data1)
summary(data1)
str(data1)
```

```{r message=FALSE}
head(data2)
summary(data2)
str(data2)
```

## Column inspection 
```{r, column_inspection}
#Checking for columns which are missing in data2
diff_cols_df1 <- setdiff(names(data1), names(data3))
cat("Columns in data1 not in data2: ", paste(diff_cols_df1, collapse = ", "), "\n")

## Checking for columns which are missing in data1
diff_cols_df3 <- setdiff(names(data3), names(data1))
cat("Columns in data2 not in data1: ", paste(diff_cols_df3, collapse = ", "), "\n")
diff_cols_df3
```

## Merge data
Now that we know both the data sets have some missing columns, lets remove them so that they can be merged. 
```{r, mergedatasets}

common_cols <- intersect(names(data1), names(data3))

data1 <- data1[, common_cols]
#data2 <- data2[, common_cols]
data3 <- data3[, common_cols]

merged_df <- rbind(data1, data3)
```


## Retain Unique records
checking for any duplicate records and keeping unique records since we merged two different source data sets
```{r, retain_uniquerecords}
cleaned_df <- unique(merged_df)
```


## removing records which are all the fossilrecords
```{r, fossilrecords}
cleaned_df <- subset(cleaned_df, basisofrecord != "FossilSpecimen")
```

## Removing Unnecessary rows
```{r}
#Let's remove question marked rows from only certain columns - like country/family/order
columns_to_check <- c("country", "order", "family")

#Let's write a function to identify "?"

has_question_mark_in_specific_columns <- function(row) {
  any(sapply(row[columns_to_check], function(col) grepl("\\?", col)))
}

#Applying function
question_mark_rows <- apply(cleaned_df, 1, has_question_mark_in_specific_columns)

#remove identified rows
cleaned_df <- cleaned_df[!question_mark_rows, ]
```


```{r}
#to remove country column entries which starts with brackets and numbers
cleaned_df <- cleaned_df %>%
  filter(!grepl("^(\\d|\\()", country)) %>%
#lets get them all to same lettering style
  mutate(country = str_to_title(country)) %>%
  mutate(country = str_replace_all(country, "([A-Z])", " \\1"))

#There seems to be a lot of full stops at the end of many countries, let's remove them
cleaned_df$country <- sub("\\.$", "", cleaned_df$country)

# Lot od square brackets in the name, let's get rid of them
cleaned_df$country <- gsub("[\\[\\]]", "", cleaned_df$country)

# Almost all the islands were abbreviated as either I or Is, Let us now rename them as Islands
cleaned_df$country <- gsub("\\bI\\b", "Islands", cleaned_df$country)
cleaned_df$country <- gsub("\\bIs\\b", "Islands", cleaned_df$country)
```

```{r}
#combine and count the unique entries of countries, Will be using this df to cross check and manually validate the country names ~ have run this after every cleaning step w.r.t country name is conducted. 
country_counts <- cleaned_df %>%
  group_by(country) %>%
  summarise(count = n())
```

================================================================================
|                                                                              |
| We are moving onto 01_01_country.Rmd script from here till we resolve all.   | 
|country names issue                                                           |
|                                                                              |
================================================================================

## Dealing with dates
```{r, warning=FALSE}
cleaned_df$year <- gsub(".*([0-9]{4}).*", "\\1", cleaned_df$year)
cleaned_df$year <- as.numeric(cleaned_df$year)

```

## Binning years into chunks of 5 year interval
```{r}
bin_width <- 5
year_range <- seq(1600, 2023, bin_width)
```

```{r}
cleaned_df$YearBin <- cut(cleaned_df$year, breaks = year_range, labels = year_range[1:(length(year_range)-1)])
```































let's write this as a working data for the time being
```{r}
write.csv(cleaned_df,"../data/cleaned_vertnet.csv", row.names = FALSE)
```



